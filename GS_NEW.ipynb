{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import array\n",
    "from keras.datasets import mnist\n",
    "import keras.utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data,train_label),(test_data,test_label) = mnist.load_data()\n",
    "train_label_data = keras.utils.to_categorical(train_label, 10)\n",
    "test_label_data = keras.utils.to_categorical(test_label, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_data = train_data.astype('float32')\n",
    "test_data_data = test_data.astype('float32')\n",
    "train_data = train_data / 255\n",
    "test_data = test_data / 255\n",
    "train_data_data = train_data.reshape(60000,784)\n",
    "test_data_data = test_data.reshape(10000,784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN:\n",
    "    def __init__(self,input_data,hidden_layer_data,output_data,learn_rate):\n",
    "        print('train_label shape:',train_label.shape)\n",
    "        self.input = input_data\n",
    "        self.hidden = hidden_layer_data\n",
    "        self.output = output_data\n",
    "        self.w1 = np.random.normal(loc = 0,scale = 0.1,size=(self.input, self.hidden))\n",
    "        print('w1_shape:',self.w1.shape)\n",
    "#         print('w1:',self.w1)\n",
    "        self.b1 = np.zeros((1,self.hidden))\n",
    "        self.w2 = np.random.normal(loc = 0,scale = 0.1,size=(self.hidden, self.output))\n",
    "        print('w2_shape:',self.w2.shape)\n",
    "#         print('w2:',self.w2)\n",
    "#         print('w2_shape:',self.w2.shape)\n",
    "        self.b2 = np.zeros((1,self.output))\n",
    "        self.lr = learn_rate\n",
    "        print('Starting ...')\n",
    "        \n",
    "    def softmax(self,k):\n",
    "        e_x = np.exp(k - np.max(k))\n",
    "        return e_x / e_x.sum(axis=0)\n",
    "\n",
    "    def softmax1(self,inputs):\n",
    "        return np.exp(inputs) / float(sum(np.exp(inputs)))\n",
    "\n",
    "    \n",
    "    def relu(self,x):\n",
    "        return np.maximum(0,x)\n",
    "    \n",
    "    def output_formula(self,input_list):\n",
    "#         print('input_list shape:',input_list.shape)\n",
    "#         print('Inputs list value:',input_list)\n",
    "        hidden_inputs = np.dot(input_list,self.w1)\n",
    "#         print('hidden inputs shape:',hidden_inputs.shape)\n",
    "#         print('hidden value:',hidden_inputs)\n",
    "        hidden_outputs = self.relu(hidden_inputs)\n",
    "#         print('hidden output shape:',hidden_outputs.shape)\n",
    "#         print('hidden output value:',hidden_outputs)\n",
    "        final_inputs = np.dot(hidden_outputs,self.w2)\n",
    "        final_inputs = np.array(final_inputs, ndmin=2).T\n",
    "#         print('final inputs shape:',final_inputs.shape)\n",
    "#         print('final inputs value:',final_inputs)\n",
    "        final_outputs = self.softmax(final_inputs)\n",
    "#         final_outputs = np.array(final_outputs, ndmin=2).T\n",
    "#         print('final outputs shape:',final_outputs.shape)\n",
    "#         print('final outputs:',final_outputs)\n",
    "        return final_outputs,hidden_outputs\n",
    "    \n",
    "    def error_formula(self,output_list,target):\n",
    "#         print('output_list',output_list)\n",
    "#         print('target:',target)\n",
    "        logprobs = -np.log(output_list[target])\n",
    "        return logprobs\n",
    "    \n",
    "    def train(self,input_list,target_list):\n",
    "#         inputs = input_list\n",
    "#         targets = target_list\n",
    "        inputs = np.array(input_list, ndmin = 2)\n",
    "        targets = np.array(target_list, ndmin = 2)\n",
    "#         print('inputs shape:',inputs.shape)\n",
    "#         print('inputs value:',inputs)\n",
    "#         print('targets shape:',targets.shape)\n",
    "#         print('targets value:',targets)\n",
    "        \n",
    "#         hidden_inputs = np.dot(self.w1,np.transpose(inputs))\n",
    "#         hidden_inputs = np.dot(inputs,self.w1)\n",
    "#         hidden_outputs = self.relu(hidden_inputs)\n",
    "#         final_inputs = np.dot(hidden_outputs,self.w2)\n",
    "#         final_outputs = self.softmax(final_inputs)\n",
    "        \n",
    "        final_outputs,hidden_outputs = self.output_formula(inputs)\n",
    "#         print('final outputs shape:',final_outputs.shape)\n",
    "#         print('final_outputs value:',final_outputs)\n",
    "#         print('hidden_outputs shape:',hidden_outputs.shape)\n",
    "#         print('hidden_outputs value:',hidden_outputs)\n",
    "        final_outputs = np.array(final_outputs, ndmin=2).T\n",
    "#         print('After ..... final_outputs shape:',final_outputs.shape)\n",
    "        output_errors = final_outputs - targets\n",
    "#         print('output_errors shape:',output_errors.shape)\n",
    "#         print('output_errors:',output_errors)\n",
    "#         print('hidden_outputs shape:',hidden_outputs.shape)\n",
    "#         print('hidden_outputs value:',hidden_outputs)\n",
    "        hidden_errors = np.dot(self.w2,np.transpose(output_errors))\n",
    "#         hidden_errors = np.array(hidden_errors, ndmin=2).T\n",
    "#         print('hidden_errors shape:',hidden_errors.shape)\n",
    "#         print('hidden errors value:',hidden_errors)\n",
    "        grad_w2 = np.dot(np.transpose(hidden_outputs),output_errors)\n",
    "#         print('grad_w2 shape:',grad_w2.shape)\n",
    "#         print('grad_w2 value:',grad_w2)\n",
    "#         inputs = np.array(inputs,ndmin=2).T\n",
    "#         print('inputs shape:',inputs.shape)\n",
    "#         print('inputs value:',inputs)\n",
    "        grad_w1 = np.dot(hidden_errors,inputs)\n",
    "        grad_w1 = np.array(grad_w1,ndmin=2).T\n",
    "#         print('grad_w1 shape:',grad_w1.shape)\n",
    "        \n",
    "        self.w2 = self.w2 - grad_w2*self.lr\n",
    "        self.w1 = self.w1 - grad_w1*self.lr\n",
    "#         hidden_errors = np.dot(self.w2,np.transpose(output_errors))\n",
    "#         grad_w2 = np.dot(np.transpose(hidden_outputs),output_errors)\n",
    "#         grad_w1 = np.dot(hidden_errors,inputs)\n",
    "        \n",
    "#         self.w2 += self.lr*grad_w2\n",
    "#         self.w1 += self.lr*np.transpose(grad_w1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_label shape: (60000,)\n",
      "w1_shape: (784, 200)\n",
      "w2_shape: (200, 10)\n",
      "Starting ...\n",
      "num: 50\n",
      "Epoch: 0\n",
      "----------------------- Size  0 . [0.14174984] --------------------------\n",
      "----------------------- Size  1 . [0.05849648] --------------------------\n",
      "----------------------- Size  2 . [0.01255024] --------------------------\n",
      "----------------------- Size  3 . [0.00782786] --------------------------\n",
      "----------------------- Size  4 . [0.00568928] --------------------------\n",
      "----------------------- Size  5 . [0.00401436] --------------------------\n",
      "----------------------- Size  6 . [0.00311195] --------------------------\n",
      "----------------------- Size  7 . [0.00260672] --------------------------\n",
      "----------------------- Size  8 . [0.0022639] --------------------------\n",
      "----------------------- Size  9 . [0.00200908] --------------------------\n",
      "----------------------- Size  10 . [0.00181004] --------------------------\n",
      "----------------------- Size  11 . [0.00164857] --------------------------\n",
      "----------------------- Size  12 . [0.00151492] --------------------------\n",
      "----------------------- Size  13 . [0.00140192] --------------------------\n",
      "----------------------- Size  14 . [0.00130504] --------------------------\n",
      "----------------------- Size  15 . [0.00122094] --------------------------\n",
      "----------------------- Size  16 . [0.00114713] --------------------------\n",
      "----------------------- Size  17 . [0.00108179] --------------------------\n",
      "----------------------- Size  18 . [0.00102347] --------------------------\n",
      "----------------------- Size  19 . [0.00097108] --------------------------\n",
      "----------------------- Size  20 . [0.00092376] --------------------------\n",
      "----------------------- Size  21 . [0.00088072] --------------------------\n",
      "----------------------- Size  22 . [0.00084147] --------------------------\n",
      "----------------------- Size  23 . [0.00080551] --------------------------\n",
      "----------------------- Size  24 . [0.00077245] --------------------------\n",
      "----------------------- Size  25 . [0.00074196] --------------------------\n",
      "----------------------- Size  26 . [0.00071374] --------------------------\n",
      "----------------------- Size  27 . [0.00068753] --------------------------\n",
      "----------------------- Size  28 . [0.00066315] --------------------------\n",
      "----------------------- Size  29 . [0.00064041] --------------------------\n",
      "----------------------- Size  30 . [0.00061915] --------------------------\n",
      "----------------------- Size  31 . [0.00059922] --------------------------\n",
      "----------------------- Size  32 . [0.00058051] --------------------------\n",
      "----------------------- Size  33 . [0.00056291] --------------------------\n",
      "----------------------- Size  34 . [0.00054632] --------------------------\n",
      "----------------------- Size  35 . [0.00053066] --------------------------\n",
      "----------------------- Size  36 . [0.00051584] --------------------------\n",
      "----------------------- Size  37 . [0.00050181] --------------------------\n",
      "----------------------- Size  38 . [0.00048849] --------------------------\n",
      "----------------------- Size  39 . [0.00047585] --------------------------\n",
      "----------------------- Size  40 . [0.00046383] --------------------------\n",
      "----------------------- Size  41 . [0.00045237] --------------------------\n",
      "----------------------- Size  42 . [0.00044146] --------------------------\n",
      "----------------------- Size  43 . [0.00043104] --------------------------\n",
      "----------------------- Size  44 . [0.00042108] --------------------------\n",
      "----------------------- Size  45 . [0.00041157] --------------------------\n",
      "----------------------- Size  46 . [0.00040245] --------------------------\n",
      "----------------------- Size  47 . [0.00039372] --------------------------\n",
      "----------------------- Size  48 . [0.00038536] --------------------------\n",
      "----------------------- Size  49 . [0.00037733] --------------------------\n",
      "****************** AVERAGE LOSS: [7.54651717e-06] *************************\n",
      "\n",
      "========== Epoch 0 ==========\n",
      "Train loss:  [7.54651717e-06]\n"
     ]
    }
   ],
   "source": [
    "input_data = 784\n",
    "hidden_layer_data = 200\n",
    "output_data = 10\n",
    "# batch_size = 100\n",
    "learning_rate = 0.1\n",
    "epochs = 1\n",
    "object1 = NN(input_data,hidden_layer_data,output_data,learning_rate)\n",
    "\n",
    "loss1 = 0\n",
    "loss_avg = 0\n",
    "last_loss = 0\n",
    "size = 100\n",
    "# num = len(training_data_list)/batch_size\n",
    "num = 50\n",
    "\n",
    "print('num:',int(num))\n",
    "\n",
    "for e in range(epochs):\n",
    "    print('Epoch:',e)\n",
    "    for i in range(int(num)):\n",
    "        loss = 0\n",
    "        for k in range(size):\n",
    "            inputs = train_data_data[k]\n",
    "            target = train_label_data[k]\n",
    "            object1.train(inputs,target)\n",
    "            out,inp = object1.output_formula(inputs)\n",
    "            loss1 = object1.error_formula(out,train_label[k])\n",
    "            loss = loss + loss1\n",
    "#             print('loss:',loss)\n",
    "        loss_avg = loss/size\n",
    "        print('----------------------- Loss ',i,'.',loss_avg,'--------------------------')\n",
    "    Loss = loss_avg/num\n",
    "    print('****************** AVERAGE LOSS:',Loss,'*************************')\n",
    "#     if e % (epochs / 10) == 0:\n",
    "    print(\"\\n========== Epoch\", e,\"==========\")\n",
    "    if last_loss and last_loss < Loss:\n",
    "        print(\"Train loss: \", Loss, \" Loss ihsej baina.\")\n",
    "    else:\n",
    "        print(\"Train loss: \", Loss)\n",
    "    last_loss = Loss\n",
    "        \n",
    "    \n",
    "# if e % (epochs / 10) == 0:\n",
    "#                 print(\"\\n========== Epoch\", e,\"==========\")\n",
    "#                 if last_loss and last_loss < Loss:\n",
    "#                     print(\"Train loss: \", Loss, \"  WARNING - Loss Increasing\")\n",
    "#                 else:\n",
    "#                     print(\"Train loss: \", Loss)\n",
    "#                 last_loss = Loss\n",
    "# inputs1 = np.array(inputs, ndmin = 2)\n",
    "# print('inputs1 shape:',inputs1.shape)\n",
    "\n",
    "# final_output = object1.output_formula(inputs1)\n",
    "# error = object1.error_formula(final_output,target)\n",
    "# print('my error:',error)\n",
    "\n",
    "# print('inputs shape:',inputs.shape)\n",
    "# print('inputs value:',inputs)\n",
    "# inputs1 = np.array(inputs, ndmin = 2)\n",
    "# print('After')\n",
    "# print('inputs1 shape:',inputs1.shape)\n",
    "# print('inputs1 value:',inputs1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
